# ğŸš€ Serveur TCP & HTTP Hautes Performances â€” C/POSIX  
### Projet IngÃ©nieur â€” Multi-threading â€¢ Queue FIFO GÃ©nÃ©rique â€¢ Benchmarks â€¢ Dashboard HTML

---

## ğŸ·ï¸ Badges GitHub

![Build](https://img.shields.io/badge/build-passing-brightgreen?style=flat-square)
![C Language](https://img.shields.io/badge/language-C-blue?style=flat-square)
![POSIX](https://img.shields.io/badge/POSIX-Compliant-orange?style=flat-square)
![Threads](https://img.shields.io/badge/Multi--threading-pthreads-purple?style=flat-square)
![Python](https://img.shields.io/badge/Benchmark-Python3-yellow?style=flat-square)
![License](https://img.shields.io/badge/license-MIT-lightgrey?style=flat-square)

---

## ğŸ¥ VidÃ©o de PrÃ©sentation

ğŸ“º **[Voir la prÃ©sentation complÃ¨te (8 min)](https://youtube.com/...)** 
*(Ã€ venir : dÃ©monstration live, architecture, rÃ©sultats benchmarks)*

---

# ğŸ“¦ RÃ©sumÃ© du projet

Ce projet implÃ©mente **quatre serveurs rÃ©seau haute performance** :

| Serveur              | Protocole | Architecture            | Fichier                    |
| -------------------- | --------- | ----------------------- | -------------------------- |
| `serveur_mono`       | TCP       | Mono-thread             | `src/serveur_mono.c`       |
| `serveur_multi`      | TCP       | Multi-thread avec queue | `src/serveur_multi.c`      |
| `serveur_mono_http`  | HTTP 1.1  | Mono-thread             | `src/serveur_mono_http.c`  |
| `serveur_multi_http` | HTTP 1.1  | Multi-thread avec queue | `src/serveur_multi_http.c` |


Le projet inclut :

âœ” Queue FIFO gÃ©nÃ©rique thread-safe (`queue.c`)

âœ” Parseur HTTP robuste (`http.c`)

âœ” Benchmarks Python (latence, CPU, mÃ©moire, RPS)

âœ” Dashboard interactif Plotly

âœ” UML gÃ©nÃ©rÃ©s automatiquement (PlantUML â†’ SVG)

âœ” Scripts DevOps & monitoring

âœ” PrÃ©sentation acadÃ©mique professionnelle
---

## ğŸ” Comparaison Technique : Mono-thread vs Multi-thread

### Architecture Globale

| Aspect | Mono-thread | Multi-thread |
|--------|-------------|--------------|
| **ModÃ¨le** | SÃ©quentiel | Producer-Consumer |
| **Threads** | 1 (main) | 9 (1 dispatcher + 8 workers) |
| **Synchronisation** | Aucune | Mutex + Cond Vars |
| **ComplexitÃ©** | Simple | Moyenne |
| **ScalabilitÃ©** | LimitÃ©e (1 CPU) | Excellente (N CPUs) |
| **Latence** | Haute sous charge | Basse et stable |
| **Throughput** | ~10 req/s | ~50-80 req/s |

### 1. CrÃ©ation et Gestion des Threads

#### Mono-thread (`serveur_mono.c`)
```c
// Traitement strictement sÃ©quentiel
for (;;) {
    int client_fd = accept(server_fd, ...);
    
    // BLOQUANT : traite 1 client Ã  la fois
    recv(client_fd, &number_net, sizeof(number_net), 0);
    traitement_lourd();  // 100ms CPU-bound
    send(client_fd, &result_net, sizeof(result_net), 0);
    
    close(client_fd);
    // Client suivant seulement APRÃˆS fermeture
}
```

**Limitation :** Avec 100 clients, temps total = 100 Ã— 100ms = **10 secondes**

#### Multi-thread (`serveur_multi.c`)
```c
// Pool de 8 workers permanents
pthread_t workers[WORKER_COUNT];
for (int i = 0; i < WORKER_COUNT; i++) {
    pthread_create(&workers[i], NULL, worker_func, NULL);
}

// Dispatcher enfile les connexions
for (;;) {
    int client_fd = accept(server_fd, ...);
    
    int *fd_ptr = malloc(sizeof(int));
    *fd_ptr = client_fd;
    
    // NON-BLOQUANT : dÃ©lÃ¨gue au worker
    queue_push(&job_queue, fd_ptr);
    // accept() immÃ©diatement disponible
}
```

**Avantage :** Avec 100 clients sur 8 workers, temps total â‰ˆ (100Ã·8) Ã— 100ms = **1.25 secondes** â†’ **8Ã— plus rapide**

### 2. Synchronisation et Zones Critiques

#### Queue FIFO Thread-Safe (`queue.c`)
```c
int queue_push(queue_t *q, void *data) {
    pthread_mutex_lock(&q->mutex);  // ğŸ”’ ENTRÃ‰E ZONE CRITIQUE
    
    // Attente active si queue pleine
    while (!q->shutdown && q->size >= q->size_max) {
        pthread_cond_wait(&q->not_full, &q->mutex);
    }
    
    if (q->shutdown) {
        pthread_mutex_unlock(&q->mutex);
        return -1;
    }
    
    // Insertion sÃ©curisÃ©e dans la liste chaÃ®nÃ©e
    queue_node_t *node = malloc(sizeof(queue_node_t));
    node->data = data;
    node->next = NULL;
    
    if (q->tail)
        q->tail->next = node;
    else
        q->head = node;
    
    q->tail = node;
    q->size++;
    
    pthread_cond_signal(&q->not_empty);  // RÃ©veille un worker
    pthread_mutex_unlock(&q->mutex);     // ğŸ”“ SORTIE ZONE CRITIQUE
    
    return 0;
}
```

**Protection garantie :**
- âœ… Aucun accÃ¨s concurrent Ã  `q->head`, `q->tail`, `q->size`
- âœ… AtomicitÃ© de l'insertion
- âœ… Signalisation automatique des workers en attente

### 3. Boucle de Traitement

#### Mono-thread : Latence Cumulative
```
Client 1 : accept â†’ traitement (100ms) â†’ rÃ©ponse â†’ close
Client 2 :           ATTEND 100ms        â†’ traitement (100ms) â†’ rÃ©ponse
Client 3 :                    ATTEND 200ms         â†’ traitement (100ms)
...
Client 100:                   ATTEND 9900ms        â†’ traitement
```
**Latence Client 100 = 9.9 secondes** âŒ

#### Multi-thread : ParallÃ©lisme RÃ©el
```
Worker 1 : Client 1 (100ms) | Client 9  (100ms) | Client 17 (100ms) ...
Worker 2 : Client 2 (100ms) | Client 10 (100ms) | Client 18 (100ms) ...
Worker 3 : Client 3 (100ms) | Client 11 (100ms) | Client 19 (100ms) ...
...
Worker 8 : Client 8 (100ms) | Client 16 (100ms) | Client 24 (100ms) ...
```
**Latence Client 100 â‰ˆ 1.25 secondes** âœ…

### 4. Structures de DonnÃ©es

#### File FIFO BornÃ©e
```c
typedef struct queue {
    queue_node_t *head;           // Premier Ã©lÃ©ment
    queue_node_t *tail;           // Dernier Ã©lÃ©ment
    pthread_mutex_t mutex;        // Protection globale
    pthread_cond_t not_empty;     // Signal pour workers
    pthread_cond_t not_full;      // Signal pour dispatcher
    bool shutdown;                // Drapeau d'arrÃªt propre
    size_t size;                  // Nombre d'Ã©lÃ©ments actuels
    size_t size_max;              // CapacitÃ© maximale (128)
} queue_t;
```

**PropriÃ©tÃ©s :**
- âœ… CapacitÃ© bornÃ©e â†’ Ã©vite saturation mÃ©moire
- âœ… FIFO strict â†’ Ã©quitÃ© de traitement
- âœ… Thread-safe â†’ utilisable par N threads
- âœ… Shutdown gracieux â†’ arrÃªt propre sans deadlock

### 5. RÃ©sultats ExpÃ©rimentaux

#### Benchmark avec 300 Clients SimultanÃ©s

| MÃ©trique | Mono-thread | Multi-thread | AmÃ©lioration |
|----------|-------------|--------------|--------------|
| **Throughput** | 9.2 req/s | 78.5 req/s | **8.5Ã—** ğŸš€ |
| **Latence P50** | 5.4 s | 0.12 s | **45Ã—** ğŸš€ |
| **Latence P99** | 29.1 s | 0.48 s | **60Ã—** ğŸš€ |
| **CPU Usage** | 12% (1 core) | 95% (8 cores) | **8Ã— mieux** |
| **Memory** | 8 MB | 12 MB | +50% acceptable |

#### Speedup ThÃ©orique vs RÃ©el
```
Speedup thÃ©orique = N workers = 8
Speedup rÃ©el mesurÃ© â‰ˆ 6.5-7.0

Perte de 12-18% due Ã  :
- Overhead de synchronisation (mutex lock/unlock)
- Context switching entre threads
- Contention sur accept() (un seul socket)
```

### 6. Cas d'Usage

#### Quand utiliser Mono-thread ?
- âœ… Charge faible (<10 req/s)
- âœ… Traitement ultra-rapide (<1ms)
- âœ… SimplicitÃ© critique (embedded systems)
- âœ… Pas besoin de scalabilitÃ©

#### Quand utiliser Multi-thread ?
- âœ… Charge Ã©levÃ©e (>50 req/s)
- âœ… Traitement CPU-bound (calculs lourds)
- âœ… Latence critique (temps de rÃ©ponse)
- âœ… Exploitation multi-cÅ“urs obligatoire

---

# ğŸ› ï¸ Installation

## âš¡ Installation Rapide

```bash
# Installation complÃ¨te en une commande
./setup.sh
```

Ou manuellement :

# 1ï¸âƒ£ PrÃ©requis
sudo apt update
sudo apt install -y build-essential python3 python3-venv python3-pip \
                   make git netcat curl


DÃ©pendances Python :

pip install psutil pandas matplotlib plotly kaleido

# 2ï¸âƒ£ Cloner le projet
git clone https://github.com/.../SERVER_BENCH.git
cd server_project

# 3ï¸âƒ£ Compiler

Mode optimisÃ© :

make -j$(nproc)


Mode debug :

make debug

# 4ï¸âƒ£ Environnement Python
cd python
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 5ï¸âƒ£ ExÃ©cuter les benchmarks
./scripts/run_all.sh


# Dashboard :

python/dashboard.html

---

# ğŸ§ª Tests Unitaires & Outils QualitÃ©

Tests queue FIFO
make test

Valgrind
valgrind --leak-check=full ./bin/serveur_multi

Helgrind
valgrind --tool=helgrind ./bin/serveur_multi

Sanitizers
make debug

# âš™ ExÃ©cution des serveurs
TCP
make run_mono
make run_multi

HTTP
make run_mono_http
make run_multi_http


# ArrÃªt :

make kill_servers

# ğŸ“‚ Arborescence du projet
"""
server_project/
â”œâ”€â”€ src/
â”œâ”€â”€ python/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CHALLENGES.md
â”‚   â”œâ”€â”€ uml/
â”‚   â”‚   â”œâ”€â”€ generate_uml.py
â”‚   â”‚   â”œâ”€â”€ uml_architecture.svg
â”‚   â”‚   â”œâ”€â”€ uml_queue.svg
â”‚   â”‚   â”œâ”€â”€ uml_threads.svg
â”‚   â”‚   â”œâ”€â”€ uml_seq_tcp_monothread.svg
â”‚   â”‚   â”œâ”€â”€ uml_seq_tcp_multithread.svg
â”‚   â”‚   â”œâ”€â”€ uml_seq_http_monothread.svg
â”‚   â”‚   â”œâ”€â”€ uml_seq_http_multithread.svg
â”‚   â”‚   â””â”€â”€ update_readme_uml.py
"""
---

#ğŸ§  UML â€” Architecture & Threads

(Section auto-gÃ©nÃ©rÃ©e par docs/uml/update_readme_uml.py)

Architecture globale
<img src="docs/uml/uml_architecture.svg" width="900">>

Queue FIFO Thread-Safe
<img src="docs/uml/uml_queue.svg" width="900">>

Multi-threading â€“ Workers & Dispatcher
<img src="docs/uml/uml_threads.svg" width="900">>

---

##SÃ©quences TCP

TCP Mono-thread
<img src="docs/uml/uml_seq_tcp_monothread.svg" width="900">>

TCP Multi-thread
<img src="docs/uml/uml_seq_tcp_multithread.svg" width="900">>

---

##SÃ©quences HTTP

HTTP Mono-thread
<img src="docs/uml/uml_seq_http_monothread.svg" width="900">>

HTTP Multi-thread
<img src="docs/uml/uml_seq_http_multithread.svg" width="900">>

#ğŸŒ API HTTP â€” Documentation ComplÃ¨te

##Routes disponibles

###Route	MÃ©thode 	Description
/	        GET	        Accueil + liste des routes
/hello	        GET	        Message JSON
/time	GET	Heure du serveur
/stats	GET	Statistiques globales

### Exemple /hello
{
  "msg": "Bonjour depuis serveur HTTP",
  "worker": "mono | pthread"
}

### Exemple /stats
{
  "total_requests": 193,
  "hello_requests": 42,
  "not_found": 3
}

# ğŸ”„ Tableau Comparatif TCP vs HTTP

CritÃ¨re	TCP (serveur_mono/multi)	HTTP 1.1 (mono/multi)
ModÃ¨le	Stream brut	RequÃªtes / RÃ©ponses JSON/HTML
Parsing	Manuel	Automatique (http.c)
Overhead	TrÃ¨s faible	Moyen
Debug	Peu lisible	TrÃ¨s lisible (curl, Browser)
Usage	Calcul distribuÃ©, RPC	API REST, tests navigateur
Messages	Binaires	Texte/JSON
Statut	Pas de notion de codes	Codes HTTP 200/404/500

# ğŸ” Analyse Technique â€” Mono-thread vs Multi-thread

## Mono-thread :

âœ” simple
âŒ scalable
âŒ chaque client attend le prÃ©cÃ©dent

## Multi-thread :

âœ” parallÃ©lisme rÃ©el
âœ” workers permanents
âœ” queue FIFO bornÃ©e
âœ” meilleure latence P99
âœ” throughput 6Ã— Ã  10Ã— supÃ©rieur

# ğŸ“Š Benchmarks (Auto-gÃ©nÃ©rÃ©s)

Les scripts Python gÃ©nÃ¨rent :

results.json

results.xlsx

python/figures/*.png

Dashboard HTML : python/dashboard.html

## Throughput (req/s)

![Throughput](python/figures/1-throughput.png)

## Latence P99

![Latency P99](python/figures/2-latency_p99.png)

## CPU Usage

![CPU](python/figures/3-cpu.png)

## MÃ©moire

![Memory](python/figures/4-memory.png)

## Speedup Multi-thread

![Speedup](python/figures/5-speedup.png)

---

## ğŸ§ª Tests et Validation

### Tests Unitaires
```bash
make test              # Tests queue FIFO
./bin/test_queue       # Tests d'intÃ©gritÃ©
```

### Tests de Charge
```bash
# Benchmark complet (10â†’300 clients)
./scripts/run_all.sh

# Test manuel mono-thread
./bin/serveur_mono &
python3 python/client_stress.py --port 5050 --clients 100

# Test manuel multi-thread
./bin/serveur_multi &
python3 python/client_stress.py --port 5051 --clients 300
```

### Validation MÃ©moire
```bash
# DÃ©tection fuites mÃ©moires
valgrind --leak-check=full ./bin/serveur_multi

# DÃ©tection race conditions
valgrind --tool=helgrind ./bin/serveur_multi

# Mode debug avec sanitizers
make debug
./bin/serveur_multi
```

---

# ğŸ› ï¸ ExÃ©cution des serveurs

```bash
make run_mono
make run_multi
make run_mono_http
make run_multi_http
```

Stopper :

```bash
make kill_servers
```

---

# ğŸ¤ PrÃ©sentation acadÃ©mique

```
presentation/presentation_finale_serveur.pptx
presentation/script_presentation.pdf
```

Inclut :

* UML
* Architecture serveur
* ExpÃ©rimentation
* Analyse des performances

---

# ğŸ‘¤ **Auteurs â€” Membres du groupe**

| Membre                 | RÃ´le                                     | Expertise                           |
| ---------------------- | ---------------------------------------- | ----------------------------------- |
| **Walid Ben Touhami**  | Serveur multi-thread, Benchmarks, DevOps | Multi-threading, queue, performance |
| **Yassin Ben Aoun**    | Parsing HTTP, serveurs HTTP              | HTTP 1.1, robustesse protocolaire   |
| **Ghada Sakouhi**      | Architecture & queue gÃ©nÃ©rique           | UML, synchronisation                |
| **Islem Ben Chaabene** | Serveur TCP mono-thread                  | C bas-niveau, sockets               |

---

## ğŸš§ DÃ©fis Techniques RencontrÃ©s

Voir : docs/CHALLENGES.md

**Outils utilisÃ©s :**
- Valgrind (memcheck + helgrind)
- GDB avec breakpoints conditionnels
- AddressSanitizer + UndefinedBehaviorSanitizer
- Tests de charge progressifs (10â†’500 clients)

---

# ğŸ“„ Licence

```
MIT License â€” Usage acadÃ©mique uniquement

```

