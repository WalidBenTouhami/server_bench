# ğŸš€ Serveur TCP & HTTP Hautes Performances â€” C/POSIX

## âš¡ Extreme Edition â€” Multi-threading Â· Queue FIFO Â· Benchmarks Â· UML Â· Mermaid Â· CI/CD

---

<p align="center">
  <img src="https://img.shields.io/badge/C89-POSIX-blue?style=flat-square"/>
  <img src="https://img.shields.io/badge/Multithreading-pthreads-purple?style=flat-square"/>
  <img src="https://img.shields.io/badge/HTTP-1.1-orange?style=flat-square"/>
  <img src="https://img.shields.io/badge/Benchmark-Python3-yellow?style=flat-square"/>
  <img src="https://img.shields.io/badge/License-MIT-lightgrey?style=flat-square"/>
</p>

---

## ğŸ”§ Badges GitHub Actions (CI/CD)

| Workflow        | Status |
|-----------------|--------|
| Build & Tests   | ![Build](https://img.shields.io/github/actions/workflow/status/WalidBenTouhami/SERVER_BENCH/build.yml?branch=main&style=flat-square) |
| Cppcheck        | ![Cppcheck](https://img.shields.io/github/actions/workflow/status/WalidBenTouhami/SERVER_BENCH/cppcheck.yml?branch=main&style=flat-square) |
| CodeQL          | ![CodeQL](https://img.shields.io/github/actions/workflow/status/WalidBenTouhami/SERVER_BENCH/codeql.yml?branch=main&style=flat-square) |
| Benchmarks      | ![Bench](https://img.shields.io/github/actions/workflow/status/WalidBenTouhami/SERVER_BENCH/benchmarks.yml?branch=main&style=flat-square) |
| Deploy Docs     | ![Deploy](https://img.shields.io/github/actions/workflow/status/WalidBenTouhami/SERVER_BENCH/deploy_docs.yml?branch=main&style=flat-square) |

**Thread-Safe Proven**
[![Thread-Safe Proven](https://img.shields.io/badge/Thread_Safe-Proven_100%25-green?style=flat-square&logo=linux)](https://github.com/WalidBenTouhami/SERVER_BENCH)
[![Zero Memory Leaks](https://img.shields.io/badge/Memory_Leaks-0_(Valgrind)-brightgreen?style=flat-square&logo=c)](https://github.com/WalidBenTouhami/SERVER_BENCH)
[![Helgrind Clean](https://img.shields.io/badge/Helgrind-0_errors-blue?style=flat-square)](https://github.com/WalidBenTouhami/SERVER_BENCH)
[![Live Demo](https://img.shields.io/badge/Live_Demo-Online-00BFFF?style=flat-square&logo=githubpages)](https://walidbentouhami.github.io/SERVER_BENCH/)

### ğŸ“Š RÃ©sultats en Temps RÃ©el

ğŸ”¥ **Throughput actuel :**  
<img src="https://raw.githubusercontent.com/WalidBenTouhami/SERVER_BENCH/main/python/figures/1-throughput.png" width="600"/>  
*(Graphique statique ; gÃ©nÃ©rÃ© via benchmarks Python â€“ voir figures/ pour live updates)*

**Documentation en ligne** â†’ <https://walidbentouhami.github.io/SERVER_BENCH/>  
*(Dashboard interactif avec rÃ©sultats, graphiques et comparaison mono/multi)*

---

## ğŸ“š Table des matiÃ¨res

1. [ğŸ¥ GIF DÃ©monstrations](#gif-dÃ©monstrations)
2. [ğŸ“¦ Projet â€” Version FR/EN](#projet--version-fren)
3. [ğŸ§  Mermaid Diagrams](#mermaid-diagrams)
4. [ğŸ“Š RÃ©sultats Benchmarks](#rÃ©sultats-benchmarks)
5. [ğŸ›  Installation & Setup](#installation--setup)
6. [ğŸ—ï¸ Build & Compilation](#build--compilation)
7. [ğŸš€ DÃ©marrage des Serveurs](#dÃ©marrage-des-serveurs)
8. [ğŸ§ª Tests & Validation](#tests--validation)
   - [Smoke Tests](#smoke-tests)
   - [Stress Tests](#stress-tests)
   - [Validation Tests](#validation-tests)
9. [ğŸ“ˆ Benchmarks & KPI](#benchmarks--kpi)
   - [Benchmarks Standards](#benchmarks-standards)
   - [Benchmarks ExtrÃªmes](#benchmarks-extrÃªmes)
   - [KPI de Performance](#kpi-de-performance)
10. [ğŸ“Š Visualisation des RÃ©sultats](#visualisation-des-rÃ©sultats)
11. [ğŸ§¹ Nettoyage du Projet](#nettoyage-du-projet)
12. [ğŸ›‘ ArrÃªt des Serveurs](#arrÃªt-des-serveurs)
13. [ğŸ¤– Scripts Disponibles](#scripts-disponibles)
14. [âš™ï¸ Workflows Automatiques](#workflows-automatiques)
15. [ğŸš€ Optimisations AppliquÃ©es](#optimisations-appliquÃ©es)
16. [ğŸ“¡ API HTTP](#api-http)
17. [ğŸ“‚ Architecture du Projet](#architecture-du-projet)
18. [ğŸš€ Pipeline DevOps Complet](#pipeline-devops-complet)
19. [ğŸ‘¤ Auteurs](#auteurs)
20. [ğŸ“œ Licence](#licence)

---

## ğŸ¥ GIF DÃ©monstrations

### Serveur TCP Multi-thread

<!-- ![server-multi](docs/gif/server_multi.gif) -->
_GIF demonstration will be added soon._

### Stress Test & Benchmarks

<!-- ![bench](docs/gif/benchmark.gif) -->
_GIF demonstration will be added soon._

---

## ğŸ“¦ Projet â€” Version FR/EN

### ğŸ‡«ğŸ‡· Version FranÃ§aise

Ce projet implÃ©mente **4 serveurs haute performance** :

| Serveur              | Protocole | Architecture        |
| -------------------- | --------- | ------------------- |
| `serveur_mono`       | TCP       | Mono-thread         |
| `serveur_multi`      | TCP       | Multi-thread + FIFO |
| `serveur_mono_http`  | HTTP 1.1  | Mono-thread         |
| `serveur_multi_http` | HTTP 1.1  | Multi-thread + FIFO |

FonctionnalitÃ©s incluses :

âœ” Multi-threading (pthread)

âœ” Queue FIFO thread-safe

âœ” HTTP router minimal

âœ” Benchmarks Python (latence, throughput, CPU, mÃ©moire)

âœ” UML + Mermaid

âœ” CI/CD GitHub complet

âœ” Pipeline DevOps automatique

âœ” PPTX & PDF auto-gÃ©nÃ©rÃ©s

### ğŸ‡¬ğŸ‡§ English Summary

This project provides **4 high-performance network servers** using POSIX sockets:

âœ” Multi-thread worker pool

âœ” Thread-safe FIFO queue

âœ” Minimal HTTP 1.1 router

âœ” Python benchmark suite

âœ” Full DevOps automation

---

## ğŸ§  Mermaid Diagrams

### Architecture Globale

```mermaid
flowchart LR
    A["Clients"] --> B["accept()"]
    B --> C["Queue FIFO (mutex + condvar)"]
    C --> D["Worker 1"]
    C --> E["Worker 2"]
    C --> F["Worker N"]
    D --> G["Traitement"]
    E --> G
    F --> G
    G --> H["send()"]
```

### Queue FIFO

```mermaid
classDiagram
    class queue_t {
        +push()
        +pop()
        +destroy()
        size
        size_max
    }
    class queue_node_t {
        data
        next
    }
    queue_t --> queue_node_t
```

### Dispatcher & Workers

```mermaid
sequenceDiagram
    Client->>Dispatcher: accept()
    Dispatcher->>Queue: push(fd)
    Queue->>Worker: pop(fd)
    Worker->>Client: send()
```

---

## ğŸ“Š RÃ©sultats Benchmarks

### Throughput

![tput](python/figures/1-throughput.png)

### Latence P99

![latency](python/figures/2-latency_p99.png)

### CPU

![cpu](python/figures/3-cpu.png)

### Memory

![mem](python/figures/4-memory.png)

---

## ğŸ›  Installation & Setup

### PrÃ©requis SystÃ¨me

```bash
# Ubuntu/Debian
sudo apt install -y build-essential python3 python3-venv python3-pip make git curl netcat-openbsd

# Fedora/RHEL
sudo dnf install -y gcc make python3 python3-pip git curl nmap-ncat
```

### Installation ComplÃ¨te

```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/WalidBenTouhami/server_bench.git
cd server_bench

# 2. Lancer le script d'installation automatique
./setup.sh
```

Le script `setup.sh` effectue automatiquement :
- âœ… VÃ©rification des dÃ©pendances systÃ¨me
- âœ… CrÃ©ation de l'environnement virtuel Python (venv)
- âœ… Installation des dÃ©pendances Python (pandas, matplotlib, psutil, etc.)
- âœ… GÃ©nÃ©ration des fichiers HTTP
- âœ… Compilation optimisÃ©e du projet C

### Installation Manuelle (si nÃ©cessaire)

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Installer les dÃ©pendances Python
pip install -r python/requirements.txt

# Compilation C
make clean
make -j$(nproc)
```

---

## ğŸ—ï¸ Build & Compilation

### Build Standard (Release)

```bash
# Nettoyage complet
make clean

# Compilation optimisÃ©e (Release mode avec -O3, -flto, -march=native)
make -j$(nproc)
```

### Build Debug (avec sanitizers)

```bash
# Mode debug avec AddressSanitizer et UndefinedBehaviorSanitizer
make MODE=debug all
```

### Cibles Makefile Disponibles

| Commande | Description |
|----------|-------------|
| `make all` | Build complet (4 serveurs + tests) |
| `make clean` | Nettoyage des binaires et objets |
| `make test` | Compilation et exÃ©cution des tests unitaires |
| `make release` | Build release avec optimisations maximales |
| `make debug` | Build debug avec sanitizers |
| `make uml` | GÃ©nÃ©ration des diagrammes UML |

### Modes de Compilation

**Mode Release (par dÃ©faut)** :
- Optimisations : `-O3 -march=native -flto -ffast-math -funroll-loops`
- SÃ©curitÃ© : `-fstack-protector-strong -Wformat-security`
- IdÃ©al pour : Production, benchmarks

**Mode Debug** :
- Debugging : `-g -O0 -DDEBUG`
- Sanitizers : `-fsanitize=address,undefined`
- IdÃ©al pour : DÃ©veloppement, dÃ©tection de bugs

---

## ğŸš€ DÃ©marrage des Serveurs

### DÃ©marrage Individuel

```bash
# Serveur TCP mono-thread (port 5050)
make run_mono
# OU
./bin/serveur_mono

# Serveur TCP multi-thread (port 5051)
make run_multi
# OU
./bin/serveur_multi

# Serveur HTTP mono-thread (port 8080)
make run_mono_http
# OU
./bin/serveur_mono_http

# Serveur HTTP multi-thread (port 8081)
make run_multi_http
# OU
./bin/serveur_multi_http
```

### DÃ©marrage Automatique (tous les serveurs)

```bash
# Option 1 : Script optimisÃ© (dÃ©marrage + monitoring)
./scripts/start_all.sh

# Option 2 : Pipeline complet (build + dÃ©marrage + benchmarks)
./scripts/run_all.sh

# Option 3 : Mode interactif (menu)
./scripts/run_interactive.sh
```

### VÃ©rification du Statut

```bash
# VÃ©rifier les processus serveurs
ps aux | grep serveur_

# VÃ©rifier les ports en Ã©coute
ss -ltnp | grep -E ":(5050|5051|8080|8081)"

# OU avec netstat
netstat -tlnp | grep -E ":(5050|5051|8080|8081)"
```

---

## ğŸ§ª Tests & Validation

### Smoke Tests

Les smoke tests permettent de vÃ©rifier le bon fonctionnement basique des serveurs.

#### Smoke Tests TCP

**TCP Mono-thread (port 5050)**

```bash
# Terminal 1 : DÃ©marrer le serveur
./bin/serveur_mono

# Terminal 2 : Tests de base
ss -ltnp | grep 5050
python3 python/client_stress_tcp.py --port 5050 --clients 1 --duration 2
```

**TCP Multi-thread (port 5051)**

```bash
# Terminal 1 : DÃ©marrer le serveur
./bin/serveur_multi

# Terminal 2 : Tests de base
ss -ltnp | grep 5051
python3 python/client_stress_tcp.py --port 5051 --clients 1 --duration 2
```

#### Smoke Tests HTTP

**HTTP Mono-thread (port 8080)**

```bash
# Terminal 1 : DÃ©marrer le serveur
./bin/serveur_mono_http

# Terminal 2 : Tests des routes
curl -v http://127.0.0.1:8080/
curl -v http://127.0.0.1:8080/hello
curl -v http://127.0.0.1:8080/time
curl -v http://127.0.0.1:8080/stats
```

**HTTP Multi-thread (port 8081)**

```bash
# Terminal 1 : DÃ©marrer le serveur
./bin/serveur_multi_http

# Terminal 2 : Tests des routes
curl -v http://127.0.0.1:8081/
curl -v http://127.0.0.1:8081/hello
curl -v http://127.0.0.1:8081/time
curl -v http://127.0.0.1:8081/stats
```

### Stress Tests

Les stress tests permettent de mesurer les performances sous charge.

#### Stress Tests TCP

```bash
# Test TCP mono-thread avec rampe de charge
python3 python/client_stress_tcp.py --port 5050 --clients 10,50,100,200

# Test TCP multi-thread avec rampe de charge
python3 python/client_stress_tcp.py --port 5051 --clients 10,50,100,200

# OU via Makefile
make stress_tcp_mono
make stress_tcp_multi
```

#### Stress Tests HTTP

```bash
# Test HTTP mono-thread
python3 python/client_stress_http.py --port 8080 --path /hello --clients 100

# Test HTTP multi-thread
python3 python/client_stress_http.py --port 8081 --path /hello --clients 100

# OU via Makefile
make stress_http_mono
make stress_http_multi
```

### Validation Tests

#### Tests Unitaires

```bash
# Compiler et exÃ©cuter les tests unitaires
make test

# OU exÃ©cuter le script de tests
./scripts/run_tests.sh
```

#### Tests MÃ©moire (Valgrind)

```bash
# DÃ©tection de fuites mÃ©moire
valgrind --leak-check=full --show-leak-kinds=all ./bin/serveur_multi

# Test de thread safety
valgrind --tool=helgrind ./bin/serveur_multi

# Test complet avec logs
valgrind --leak-check=full --log-file=valgrind.log ./bin/serveur_multi

# Script automatique de rapport Valgrind
./scripts/valgrind_report.sh
```

#### Build avec Sanitizers

```bash
# Compilation avec AddressSanitizer et UndefinedBehaviorSanitizer
make MODE=debug all

# ExÃ©cution avec dÃ©tection automatique des erreurs
./bin/serveur_multi
```

---

## ğŸ“ˆ Benchmarks & KPI

### Benchmarks Standards

```bash
# Benchmark complet avec tous les serveurs
python3 python/benchmark.py

# GÃ©nÃ©ration des graphiques
python3 python/plot_results.py

# Export HTML interactif
python3 python/export_html.py
```

### Benchmarks ExtrÃªmes

```bash
# Benchmarks avec charges maximales
python3 python/benchmark_extreme.py

# OU via Makefile
make benchmark_extreme

# OU via pipeline complet
./scripts/run_all.sh
```

### KPI de Performance

Les benchmarks capturent les KPI suivants :

| KPI | Description | UnitÃ© |
|-----|-------------|-------|
| **Throughput** | Nombre de requÃªtes/sec traitÃ©es | req/s |
| **Latence moyenne** | Temps de rÃ©ponse moyen | ms |
| **Latence P50** | MÃ©diane des temps de rÃ©ponse | ms |
| **Latence P95** | 95e percentile | ms |
| **Latence P99** | 99e percentile | ms |
| **CPU Usage** | Utilisation CPU moyenne | % |
| **Memory Usage** | Consommation mÃ©moire | MB |
| **Success Rate** | Taux de succÃ¨s des requÃªtes | % |
| **Error Rate** | Taux d'erreur | % |
| **Connections/sec** | Nouvelles connexions par seconde | conn/s |

### RÃ©sultats ExportÃ©s

```bash
# Fichiers gÃ©nÃ©rÃ©s aprÃ¨s benchmark
python/results.json       # RÃ©sultats bruts (JSON)
python/results.xlsx       # RÃ©sultats exportÃ©s (Excel)
python/dashboard.html     # Dashboard interactif

# Graphiques gÃ©nÃ©rÃ©s
python/figures/1-throughput.png    # DÃ©bit
python/figures/2-latency_p99.png   # Latence P99
python/figures/3-cpu.png           # Utilisation CPU
python/figures/4-memory.png        # Utilisation mÃ©moire
python/figures/5-speedup.png       # Speedup mono vs multi
python/figures/6-saturation.png    # Courbe de saturation
```

---

## ğŸ“Š Visualisation des RÃ©sultats

### Dashboard Interactif

```bash
# Ouvrir le dashboard HTML dans le navigateur
./scripts/open_dashboard.sh

# OU manuellement
firefox python/dashboard.html
# OU
chromium-browser python/dashboard.html
```

### Inspection Rapide des RÃ©sultats

```bash
# Afficher un rÃ©sumÃ© des rÃ©sultats
./scripts/view_results.sh

# Afficher les graphiques
xdg-open python/figures/1-throughput.png
xdg-open python/figures/2-latency_p99.png
```

### Documentation En Ligne

Dashboard GitHub Pages : <https://walidbentouhami.github.io/SERVER_BENCH/>

---

## ğŸ§¹ Nettoyage du Projet

### Nettoyage Standard

```bash
# Nettoyer les binaires et objets compilÃ©s
make clean

# OU via script
./scripts/clean_project.sh
```

### Nettoyage Complet

```bash
# Nettoyage complet (inclut logs, figures, rÃ©sultats)
./scripts/clean_project.sh --deep

# Mode dry-run (voir ce qui serait supprimÃ©)
./scripts/clean_project.sh --dry-run

# Nettoyage verbeux
./scripts/clean_project.sh --verbose
```

### Fichiers NettoyÃ©s

- `build/` : Fichiers objets (.o)
- `bin/` : Binaires compilÃ©s
- `python/figures/` : Graphiques gÃ©nÃ©rÃ©s
- `python/results.json` : RÃ©sultats JSON
- `python/results.xlsx` : RÃ©sultats Excel
- `logs/` : Fichiers de logs

---

## ğŸ›‘ ArrÃªt des Serveurs

### ArrÃªt Propre (RecommandÃ©)

```bash
# ArrÃªt de tous les serveurs via Makefile
make kill_servers

# OU via script
./scripts/kill_servers.sh
```

### ArrÃªt Manuel

```bash
# Identifier les PIDs des serveurs
ps aux | grep serveur_

# ArrÃªt propre (SIGINT)
kill -SIGINT <PID>

# ArrÃªt forcÃ© (SIGKILL - dernier recours)
kill -9 <PID>
```

---

## ğŸ¤– Scripts Disponibles

| Script | Description |
|--------|-------------|
| `setup.sh` | Installation complÃ¨te du projet |
| `scripts/start_all.sh` | DÃ©marrage de tous les serveurs |
| `scripts/run_all.sh` | Pipeline complet (build + bench + plots) |
| `scripts/run_interactive.sh` | Menu interactif |
| `scripts/run_servers.sh` | DÃ©marrage manuel des serveurs |
| `scripts/run_tests.sh` | ExÃ©cution des tests unitaires |
| `scripts/kill_servers.sh` | ArrÃªt propre des serveurs |
| `scripts/clean_project.sh` | Nettoyage du projet |
| `scripts/view_results.sh` | Inspection des rÃ©sultats |
| `scripts/open_dashboard.sh` | Ouverture du dashboard HTML |
| `scripts/valgrind_report.sh` | Rapport Valgrind |
| `scripts/generate_uml.sh` | GÃ©nÃ©ration UML |

### Utilisation du Mode Interactif

```bash
./scripts/run_interactive.sh
```

Menu disponible :
1. **FULL RUN** â€“ Tout exÃ©cuter (build + UML + serveurs + benchmarks)
2. **Build seul** â€“ Compilation optimisÃ©e
3. **GÃ©nÃ©rer UML** â€“ Diagrammes + README
4. **GÃ©nÃ©rer prÃ©sentation** â€“ PPTX + PDF
5. **DÃ©marrer serveurs** â€“ Tous les serveurs
6. **Smoke tests** â€“ Tests HTTP
7. **Stress tests** â€“ TCP + HTTP
8. **Benchmarks EXTREME** â€“ Charge maximale
9. **Statut serveurs** â€“ Processus + ports
k. **Kill serveurs** â€“ ArrÃªt propre
q. **Quitter**

---

## âš™ï¸ Workflows Automatiques

### Workflows GitHub Actions

| Workflow | Trigger | Description |
|----------|---------|-------------|
| **build.yml** | Push, PR | Build et tests unitaires |
| **cppcheck.yml** | Push (src/) | Analyse statique C |
| **codeql.yml** | Push, Schedule | Analyse sÃ©curitÃ© CodeQL |
| **benchmarks.yml** | Schedule, Manual | Benchmarks automatiques |
| **deploy_docs.yml** | Push (docs/) | DÃ©ploiement GitHub Pages |

### Pipeline Local Complet

```bash
# Pipeline automatique complet
./scripts/run_all.sh

# Contenu du pipeline :
# 1. VÃ©rification venv Python
# 2. Compilation C optimisÃ©e (-j)
# 3. ExÃ©cution benchmark.py
# 4. GÃ©nÃ©ration graphiques (plot_results.py)
# 5. Export dashboard HTML (export_html.py)
```

---

## ğŸš€ Optimisations AppliquÃ©es

Le projet utilise des optimisations avancÃ©es pour des performances maximales.

### Optimisations de Compilation

| Flag | Description |
|------|-------------|
| `-O3` | Optimisations maximales du compilateur |
| `-march=native` | Optimisations spÃ©cifiques Ã  l'architecture CPU |
| `-flto` | Link-Time Optimization inter-modules |
| `-ffast-math` | Optimisations mathÃ©matiques rapides |
| `-funroll-loops` | DÃ©roulement de boucles |
| `-DNDEBUG` | DÃ©sactivation des assertions (release) |

### Optimisations RÃ©seau

- **TCP_NODELAY** : DÃ©sactivation de l'algorithme de Nagle pour latence minimale
- **SO_REUSEADDR** : RÃ©utilisation immÃ©diate des sockets
- **Non-blocking I/O** : Gestion asynchrone des connexions
- **Connection pooling** : RÃ©utilisation des threads workers

### Optimisations Multi-threading

- **Queue FIFO thread-safe** : Mutex + condition variables
- **Worker pool** : Threads prÃ©-allouÃ©s (pas de crÃ©ation dynamique)
- **Load balancing** : Distribution Ã©quitable via queue FIFO
- **Lock-free operations** : Minimisation des sections critiques

### SÃ©curitÃ© et Robustesse

| MÃ©canisme | Description |
|-----------|-------------|
| **Signal handling** | `SIGPIPE` ignorÃ© (connexions fermÃ©es) |
| **MSG_NOSIGNAL** | PrÃ©vention des crashes sur socket fermÃ© |
| **Stack protector** | `-fstack-protector-strong` |
| **Format security** | `-Wformat=2 -Wformat-security` |
| **Mutex errorcheck** | DÃ©tection d'erreurs de verrouillage |

### Optimisations Python

- **Parallel execution** : `make -j$(nproc)`
- **Matplotlib Agg backend** : GÃ©nÃ©ration sans display
- **Buffering** : Buffers 8KB pour I/O rÃ©seau
- **Connection pooling** : MAX_WORKERS=500

---

## ğŸ“¡ API HTTP

### Routes Disponibles

| Route | MÃ©thode | Description | Exemple |
|-------|---------|-------------|---------|
| `/` | GET | Page d'accueil | `curl http://127.0.0.1:8080/` |
| `/hello` | GET | Message JSON | `curl http://127.0.0.1:8080/hello` |
| `/time` | GET | Timestamp serveur | `curl http://127.0.0.1:8080/time` |
| `/stats` | GET | Statistiques serveur | `curl http://127.0.0.1:8080/stats` |

### Exemples de RÃ©ponses

**Route `/hello`**

```json
{
  "msg": "Hello from HTTP server",
  "requests": 128,
  "worker": 3
}
```

**Route `/time`**

```json
{
  "timestamp": 1702387200,
  "iso": "2023-12-12T10:00:00Z"
}
```

**Route `/stats`**

```json
{
  "requests_total": 1542,
  "requests_success": 1540,
  "requests_failed": 2,
  "uptime_seconds": 3600,
  "workers_active": 4
}
```

### Test Complet de l'API

```bash
# DÃ©marrer le serveur HTTP multi-thread
./bin/serveur_multi_http

# Tests des routes (dans un autre terminal)
curl -v http://127.0.0.1:8081/
curl http://127.0.0.1:8081/hello | jq .
curl http://127.0.0.1:8081/time | jq .
curl http://127.0.0.1:8081/stats | jq .
```

---

## ğŸ“‚ Architecture du Projet

### Structure des RÃ©pertoires

```
server_bench/
â”œâ”€â”€ src/                          # Code source C
â”‚   â”œâ”€â”€ http.c / http.h           # Parser HTTP 1.1
â”‚   â”œâ”€â”€ queue.c / queue.h         # Queue FIFO thread-safe
â”‚   â”œâ”€â”€ serveur_mono.c            # Serveur TCP mono-thread
â”‚   â”œâ”€â”€ serveur_multi.c           # Serveur TCP multi-thread
â”‚   â”œâ”€â”€ serveur_mono_http.c       # Serveur HTTP mono-thread
â”‚   â””â”€â”€ serveur_multi_http.c      # Serveur HTTP multi-thread
â”‚
â”œâ”€â”€ tests/                        # Tests unitaires
â”‚   â””â”€â”€ test_queue.c              # Tests queue FIFO
â”‚
â”œâ”€â”€ python/                       # Scripts Python
â”‚   â”œâ”€â”€ benchmark.py              # Benchmark standard
â”‚   â”œâ”€â”€ benchmark_extreme.py      # Benchmark extrÃªme
â”‚   â”œâ”€â”€ client_stress_tcp.py      # Client stress TCP
â”‚   â”œâ”€â”€ client_stress_http.py     # Client stress HTTP
â”‚   â”œâ”€â”€ plot_results.py           # GÃ©nÃ©ration graphiques
â”‚   â”œâ”€â”€ export_html.py            # Export dashboard HTML
â”‚   â”œâ”€â”€ figures/                  # Graphiques gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ results.json              # RÃ©sultats bruts
â”‚   â””â”€â”€ results.xlsx              # RÃ©sultats Excel
â”‚
â”œâ”€â”€ scripts/                      # Scripts shell
â”‚   â”œâ”€â”€ setup.sh                  # Installation
â”‚   â”œâ”€â”€ run_all.sh                # Pipeline complet
â”‚   â”œâ”€â”€ start_all.sh              # DÃ©marrage serveurs
â”‚   â”œâ”€â”€ run_interactive.sh        # Menu interactif
â”‚   â”œâ”€â”€ run_tests.sh              # Tests unitaires
â”‚   â”œâ”€â”€ kill_servers.sh           # ArrÃªt serveurs
â”‚   â”œâ”€â”€ clean_project.sh          # Nettoyage
â”‚   â”œâ”€â”€ view_results.sh           # Visualisation
â”‚   â”œâ”€â”€ open_dashboard.sh         # Dashboard HTML
â”‚   â””â”€â”€ valgrind_report.sh        # Rapport mÃ©moire
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ uml/                      # Diagrammes UML
â”‚   â”œâ”€â”€ AUDIT_REPORT.md           # Rapport d'audit
â”‚   â”œâ”€â”€ VALIDATION_CHECKLIST.md   # Checklist validation
â”‚   â””â”€â”€ cheatsheet.pdf            # Aide-mÃ©moire
â”‚
â”œâ”€â”€ .github/workflows/            # CI/CD GitHub Actions
â”‚   â”œâ”€â”€ build.yml                 # Build & tests
â”‚   â”œâ”€â”€ cppcheck.yml              # Analyse statique
â”‚   â”œâ”€â”€ codeql.yml                # Analyse sÃ©curitÃ©
â”‚   â”œâ”€â”€ benchmarks.yml            # Benchmarks auto
â”‚   â””â”€â”€ deploy_docs.yml           # DÃ©ploiement docs
â”‚
â”œâ”€â”€ build/                        # Fichiers objets (.o)
â”œâ”€â”€ bin/                          # Binaires compilÃ©s
â”œâ”€â”€ logs/                         # Fichiers de logs
â”œâ”€â”€ venv/                         # Environnement Python
â”‚
â”œâ”€â”€ Makefile                      # Build system
â”œâ”€â”€ README.md                     # Ce fichier
â””â”€â”€ setup.sh                      # Installation automatique
```

### Modules C

| Module | Fichiers | Description |
|--------|----------|-------------|
| **Queue FIFO** | `queue.c/h` | Queue thread-safe avec mutex + condvar |
| **HTTP Parser** | `http.c/h` | Parser HTTP 1.1 minimal (GET) |
| **TCP Mono** | `serveur_mono.c` | Serveur TCP single-threaded |
| **TCP Multi** | `serveur_multi.c` | Serveur TCP multi-threaded + pool |
| **HTTP Mono** | `serveur_mono_http.c` | Serveur HTTP single-threaded |
| **HTTP Multi** | `serveur_multi_http.c` | Serveur HTTP multi-threaded + pool |

---

## ğŸš€ Pipeline DevOps Complet

### Pipeline Automatique

Le script `run_interactive.sh` orchestre l'ensemble du pipeline DevOps :

```bash
./scripts/run_interactive.sh
```

**Ã‰tapes exÃ©cutÃ©es automatiquement** :

| Ã‰tape | Description |
|-------|-------------|
| âœ… **Setup venv** | VÃ©rification environnement Python |
| âœ… **GÃ©nÃ©ration HTTP** | CrÃ©ation fichiers HTTP dynamiques |
| âœ… **Build C** | Compilation optimisÃ©e (-O3 + LTO) |
| âœ… **GÃ©nÃ©ration UML** | Diagrammes PUML + SVG |
| âœ… **GÃ©nÃ©ration Docs** | PPTX + PDF de prÃ©sentation |
| âœ… **DÃ©marrage serveurs** | Lancement des 4 serveurs (TCP + HTTP) |
| âœ… **Smoke tests** | Tests `/`, `/hello`, `/time`, `/stats` |
| âœ… **Stress tests** | Tests TCP + HTTP sous charge |
| âœ… **Benchmarks extrÃªmes** | Mesure performances maximales |
| âœ… **Monitoring** | Capture CPU/RAM en temps rÃ©el |
| âœ… **Export rÃ©sultats** | JSON, XLSX, Graphiques, Dashboard HTML |
| âœ… **ArrÃªt propre** | Kill propre avec SIGINT |

### Pipeline CI/CD GitHub

**Workflows automatiques** :

- **build.yml** : Build + tests Ã  chaque push
- **cppcheck.yml** : Analyse statique du code C
- **codeql.yml** : Scan de sÃ©curitÃ© CodeQL
- **benchmarks.yml** : Benchmarks schedulÃ©s
- **deploy_docs.yml** : DÃ©ploiement GitHub Pages

**DÃ©clenchement** :
- Push sur `main`
- Pull requests
- Schedule (quotidien pour benchmarks)
- Manual dispatch

---

## ğŸ‘¤ Auteurs

| Auteur | RÃ´le | Expertise |
|--------|------|-----------|
| **Walid Ben Touhami** | DevOps, Multi-threading, Benchmarks | High-performance systems |
| **Yassin Ben Aoun** | HTTP parser | Protocol engineering |
| **Ghada Sakouhi** | FIFO queue, UML | Software architecture |
| **Islem Ben Chaabene** | TCP mono-thread | POSIX networking |

---

## ğŸ“œ Licence

```
MIT License â€” Academic Use Only
```

---

## ğŸ“ Support & Contribution

### Questions & Issues

Ouvrir une issue sur GitHub : <https://github.com/WalidBenTouhami/server_bench/issues>

### Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Documentation ComplÃ¨te

- **GitHub Pages** : <https://walidbentouhami.github.io/SERVER_BENCH/>
- **Audit Report** : `docs/AUDIT_REPORT.md`
- **Validation Checklist** : `docs/VALIDATION_CHECKLIST.md`
- **Cheatsheet** : `docs/cheatsheet.pdf`

---

**ğŸš€ PrÃªt Ã  dÃ©marrer ? ExÃ©cutez `./setup.sh` puis `./scripts/run_interactive.sh` !**
