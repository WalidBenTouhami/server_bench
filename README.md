# ðŸš€ Serveur TCP & HTTP Hautes Performances â€” C/POSIX

## âš¡ Extreme Edition â€” Multi-threading Â· Queue FIFO Â· Benchmarks Â· UML Â· Mermaid Â· CI/CD

---

<p align="center">
  <img src="https://img.shields.io/badge/C89-POSIX-blue?style=flat-square"/>
  <img src="https://img.shields.io/badge/Multithreading-pthreads-purple?style=flat-square"/>
  <img src="https://img.shields.io/badge/HTTP-1.1-orange?style=flat-square"/>
  <img src="https://img.shields.io/badge/Benchmark-Python3-yellow?style=flat-square"/>
  <img src="https://img.shields.io/badge/License-MIT-lightgrey?style=flat-square"/>
</p>

---

# ðŸ”§ Badges GitHub Actions (CI/CD)

# SERVER_BENCH â€“ Comparaison mono-thread vs multi-thread (C + pthread)

![Build & Tests](https://github.com/WalidBenTouhami/SERVER_BENCH/workflows/Build%20&%20Test/badge.svg)
![Cppcheck](https://github.com/WalidBenTouhami/SERVER_BENCH/workflows/Cppcheck%20Analysis/badge.svg)
![CodeQL](https://github.com/WalidBenTouhami/SERVER_BENCH/workflows/CodeQL%20Security%20Scan/badge.svg)
![Benchmarks](https://github.com/WalidBenTouhami/SERVER_BENCH/workflows/Benchmarks/badge.svg)

**Performance actuelle (mise Ã  jour automatique) :**  
![Throughput](https://img.shields.io/badge/throughput-XXX%20req/s-brightgreen)  
(rafraÃ®chit Ã  chaque push sur main)

---

# ðŸ“š Table des matiÃ¨res

* [ðŸŽ¥ GIF DÃ©monstrations](#-gif-dÃ©monstrations)
* [ðŸ“¦ Projet â€” Version FR/EN](#-projet--version-fren)
* [ðŸ§  Mermaid Diagrams](#-mermaid-diagrams)
* [ðŸ“Š Benchmarks](#-benchmarks)
* [ðŸ›  Installation](#-installation)
* [âš™ ExÃ©cution](#-exÃ©cution)
* [ðŸ§ª Tests & Validation](#-tests--validation)
* [ðŸ“¡ API HTTP](#-api-http)
* [ðŸ“‚ Architecture du projet](#-architecture-du-projet)
* [ðŸš€ Pipeline DevOps complet](#-pipeline-devops-complet)
* [ðŸ‘¤ Auteurs](#-auteurs)
* [ðŸ“œ Licence](#-licence)

---

# ðŸŽ¥ GIF DÃ©monstrations

### Serveur TCP Multi-thread

![server-multi](docs/gif/server_multi.gif)

### Stress Test & Benchmarks

![bench](docs/gif/benchmark.gif)

---

# ðŸ“¦ Projet â€” Version FR/EN

## ðŸ‡«ðŸ‡· Version FranÃ§aise

Ce projet implÃ©mente **4 serveurs haute performance** :

| Serveur              | Protocole | Architecture        |
| -------------------- | --------- | ------------------- |
| `serveur_mono`       | TCP       | Mono-thread         |
| `serveur_multi`      | TCP       | Multi-thread + FIFO |
| `serveur_mono_http`  | HTTP 1.1  | Mono-thread         |
| `serveur_multi_http` | HTTP 1.1  | Multi-thread + FIFO |

FonctionnalitÃ©s incluses :

âœ” Multi-threading (pthread)
âœ” Queue FIFO thread-safe
âœ” HTTP router minimal
âœ” Benchmarks Python (latence, throughput, CPU, mÃ©moire)
âœ” UML + Mermaid
âœ” CI/CD GitHub complet
âœ” Pipeline DevOps automatique
âœ” PPTX & PDF auto-gÃ©nÃ©rÃ©s

---

## ðŸ‡¬ðŸ‡§ English Summary

This project provides **4 high-performance network servers** using POSIX sockets:

âœ” Multi-thread worker pool
âœ” Thread-safe FIFO queue
âœ” Minimal HTTP 1.1 router
âœ” Python benchmark suite
âœ” Full DevOps automation

---

# ðŸ§  Mermaid Diagrams

## Architecture Globale

```mermaid
flowchart LR
    A["Clients"] --> B["accept()"]
    B --> C["Queue FIFO (mutex + condvar)"]
    C --> D["Worker 1"]
    C --> E["Worker 2"]
    C --> F["Worker N"]
    D --> G["Traitement"]
    E --> G
    F --> G
    G --> H["send()"]
```

## Queue FIFO

```mermaid
classDiagram
    class queue_t {
        +push()
        +pop()
        +destroy()
        size
        size_max
    }
    class queue_node_t {
        data
        next
    }
    queue_t --> queue_node_t
```

## Dispatcher & Workers

```mermaid
sequenceDiagram
    Client->>Dispatcher: accept()
    Dispatcher->>Queue: push(fd)
    Queue->>Worker: pop(fd)
    Worker->>Client: send()
```

---

# ðŸ“Š Benchmarks

### Throughput

![tput](python/figures/1-throughput.png)

### Latence P99

![latency](python/figures/2-latency_p99.png)

### CPU

![cpu](python/figures/3-cpu.png)

### Memory

![mem](python/figures/4-memory.png)

---

# ðŸ›  Installation

```bash
sudo apt install build-essential python3 python3-venv python3-pip
git clone https://github.com/WalidBenTouhami/SERVER_BENCH.git
cd SERVER_BENCH
make -j$(nproc)
```

---

# âš™ ExÃ©cution

```bash
make run_mono
make run_multi
make run_mono_http
make run_multi_http
```

---

# ðŸ§ª Tests & Validation

```bash
make test
valgrind --leak-check=full ./bin/serveur_multi
valgrind --tool=helgrind ./bin/serveur_multi
make debug
```

---

# ðŸ“¡ API HTTP

| Route    | Description  |
| -------- | ------------ |
| `/`      | Accueil      |
| `/hello` | JSON         |
| `/time`  | Timestamp    |
| `/stats` | Statistiques |

Example:

```json
{
  "msg": "Hello from HTTP server",
  "requests": 128,
  "worker": 3
}
```

---

# ðŸ“‚ Architecture du projet

```
src/
â”œâ”€â”€ http.c / http.h
â”œâ”€â”€ queue.c / queue.h
â”œâ”€â”€ serveur_mono.c
â”œâ”€â”€ serveur_multi.c
â”œâ”€â”€ serveur_mono_http.c
â””â”€â”€ serveur_multi_http.c
```

---

# ðŸš€ Pipeline DevOps complet

### ExÃ©cution globale :

```bash
./scripts/run_interactive.sh
```

Il exÃ©cute automatiquement :

âœ” GÃ©nÃ©ration HTTP
âœ” Build C (O3 + LTO)
âœ” GÃ©nÃ©ration UML
âœ” GÃ©nÃ©ration PPTX + PDF
âœ” DÃ©marrage serveurs
âœ” Tests `/`, `/hello`, `/time`, `/stats`
âœ” Stress tests TCP/HTTP
âœ” Benchmarks extrÃªmes
âœ” Monitoring CPU/RAM
âœ” Kill propre multi-thread

---

# ðŸ‘¤ Auteurs

| Auteur                 | RÃ´le                                | Expertise                |
| ---------------------- | ----------------------------------- | ------------------------ |
| **Walid Ben Touhami**  | DevOps, Multi-threading, Benchmarks | High-performance systems |
| **Yassin Ben Aoun**    | HTTP parser                         | Protocol engineering     |
| **Ghada Sakouhi**      | FIFO queue, UML                     | Software architecture    |
| **Islem Ben Chaabene** | TCP mono-thread                     | POSIX networking         |

---

# ðŸ“œ Licence

```
MIT License â€” Academic Use Only
```

---

