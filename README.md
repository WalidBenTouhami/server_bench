# ğŸš€ Serveur TCP & HTTP Hautes Performances â€” C/POSIX  
### Projet IngÃ©nieur â€” Multi-threading â€¢ Queue FIFO GÃ©nÃ©rique â€¢ Benchmarks â€¢ Dashboard HTML

---

## ğŸ·ï¸ Badges GitHub

![Build](https://img.shields.io/badge/build-passing-brightgreen?style=flat-square)
![C Language](https://img.shields.io/badge/language-C-blue?style=flat-square)
![POSIX](https://img.shields.io/badge/POSIX-Compliant-orange?style=flat-square)
![Threads](https://img.shields.io/badge/Multi--threading-pthreads-purple?style=flat-square)
![Python](https://img.shields.io/badge/Benchmark-Python3-yellow?style=flat-square)
![License](https://img.shields.io/badge/license-MIT-lightgrey?style=flat-square)

---

## ğŸ¥ VidÃ©o de PrÃ©sentation

ğŸ“º **[Voir la prÃ©sentation complÃ¨te (8 min)](https://youtube.com/...)** 
*(Ã€ venir : dÃ©monstration live, architecture, rÃ©sultats benchmarks)*

---

# ğŸ“¦ RÃ©sumÃ© du projet

Ce projet implÃ©mente **quatre serveurs rÃ©seau haute performance** en C/POSIX :

| Serveur | Protocole | Architecture | Fichier |
|--------|-----------|--------------|---------|
| `serveur_mono` | TCP | Mono-thread | `src/serveur_mono.c` |
| `serveur_multi` | TCP | Multi-thread + queue | `src/serveur_multi.c` |
| `serveur_mono_http` | HTTP 1.1 | Mono-thread | `src/serveur_mono_http.c` |
| `serveur_multi_http` | HTTP 1.1 | Multi-thread + queue | `src/serveur_multi_http.c` |

Le projet inclut :

- âœ” File FIFO gÃ©nÃ©rique thread-safe (`queue.c`)
- âœ” Parseur HTTP robuste (`http.c`)
- âœ” Benchmarks Python (latence, CPU, RAM, RPS)
- âœ” Dashboard interactif Plotly HTML
- âœ” Scripts DevOps (run_all, monitoring, auto-rebuild)
- âœ” PrÃ©sentation acadÃ©mique PPTX + script PDF

---

## ğŸ” Comparaison Technique : Mono-thread vs Multi-thread

### Architecture Globale

| Aspect | Mono-thread | Multi-thread |
|--------|-------------|--------------|
| **ModÃ¨le** | SÃ©quentiel | Producer-Consumer |
| **Threads** | 1 (main) | 9 (1 dispatcher + 8 workers) |
| **Synchronisation** | Aucune | Mutex + Cond Vars |
| **ComplexitÃ©** | Simple | Moyenne |
| **ScalabilitÃ©** | LimitÃ©e (1 CPU) | Excellente (N CPUs) |
| **Latence** | Haute sous charge | Basse et stable |
| **Throughput** | ~10 req/s | ~50-80 req/s |

### 1. CrÃ©ation et Gestion des Threads

#### Mono-thread (`serveur_mono.c`)
```c
// Traitement strictement sÃ©quentiel
for (;;) {
    int client_fd = accept(server_fd, ...);
    
    // BLOQUANT : traite 1 client Ã  la fois
    recv(client_fd, &number_net, sizeof(number_net), 0);
    traitement_lourd();  // 100ms CPU-bound
    send(client_fd, &result_net, sizeof(result_net), 0);
    
    close(client_fd);
    // Client suivant seulement APRÃˆS fermeture
}
```

**Limitation :** Avec 100 clients, temps total = 100 Ã— 100ms = **10 secondes**

#### Multi-thread (`serveur_multi.c`)
```c
// Pool de 8 workers permanents
pthread_t workers[WORKER_COUNT];
for (int i = 0; i < WORKER_COUNT; i++) {
    pthread_create(&workers[i], NULL, worker_func, NULL);
}

// Dispatcher enfile les connexions
for (;;) {
    int client_fd = accept(server_fd, ...);
    
    int *fd_ptr = malloc(sizeof(int));
    *fd_ptr = client_fd;
    
    // NON-BLOQUANT : dÃ©lÃ¨gue au worker
    queue_push(&job_queue, fd_ptr);
    // accept() immÃ©diatement disponible
}
```

**Avantage :** Avec 100 clients sur 8 workers, temps total â‰ˆ (100Ã·8) Ã— 100ms = **1.25 secondes** â†’ **8Ã— plus rapide**

### 2. Synchronisation et Zones Critiques

#### Queue FIFO Thread-Safe (`queue.c`)
```c
int queue_push(queue_t *q, void *data) {
    pthread_mutex_lock(&q->mutex);  // ğŸ”’ ENTRÃ‰E ZONE CRITIQUE
    
    // Attente active si queue pleine
    while (!q->shutdown && q->size >= q->size_max) {
        pthread_cond_wait(&q->not_full, &q->mutex);
    }
    
    if (q->shutdown) {
        pthread_mutex_unlock(&q->mutex);
        return -1;
    }
    
    // Insertion sÃ©curisÃ©e dans la liste chaÃ®nÃ©e
    queue_node_t *node = malloc(sizeof(queue_node_t));
    node->data = data;
    node->next = NULL;
    
    if (q->tail)
        q->tail->next = node;
    else
        q->head = node;
    
    q->tail = node;
    q->size++;
    
    pthread_cond_signal(&q->not_empty);  // RÃ©veille un worker
    pthread_mutex_unlock(&q->mutex);     // ğŸ”“ SORTIE ZONE CRITIQUE
    
    return 0;
}
```

**Protection garantie :**
- âœ… Aucun accÃ¨s concurrent Ã  `q->head`, `q->tail`, `q->size`
- âœ… AtomicitÃ© de l'insertion
- âœ… Signalisation automatique des workers en attente

### 3. Boucle de Traitement

#### Mono-thread : Latence Cumulative
```
Client 1 : accept â†’ traitement (100ms) â†’ rÃ©ponse â†’ close
Client 2 :           ATTEND 100ms        â†’ traitement (100ms) â†’ rÃ©ponse
Client 3 :                    ATTEND 200ms         â†’ traitement (100ms)
...
Client 100:                   ATTEND 9900ms        â†’ traitement
```
**Latence Client 100 = 9.9 secondes** âŒ

#### Multi-thread : ParallÃ©lisme RÃ©el
```
Worker 1 : Client 1 (100ms) | Client 9  (100ms) | Client 17 (100ms) ...
Worker 2 : Client 2 (100ms) | Client 10 (100ms) | Client 18 (100ms) ...
Worker 3 : Client 3 (100ms) | Client 11 (100ms) | Client 19 (100ms) ...
...
Worker 8 : Client 8 (100ms) | Client 16 (100ms) | Client 24 (100ms) ...
```
**Latence Client 100 â‰ˆ 1.25 secondes** âœ…

### 4. Structures de DonnÃ©es

#### File FIFO BornÃ©e
```c
typedef struct queue {
    queue_node_t *head;           // Premier Ã©lÃ©ment
    queue_node_t *tail;           // Dernier Ã©lÃ©ment
    pthread_mutex_t mutex;        // Protection globale
    pthread_cond_t not_empty;     // Signal pour workers
    pthread_cond_t not_full;      // Signal pour dispatcher
    bool shutdown;                // Drapeau d'arrÃªt propre
    size_t size;                  // Nombre d'Ã©lÃ©ments actuels
    size_t size_max;              // CapacitÃ© maximale (128)
} queue_t;
```

**PropriÃ©tÃ©s :**
- âœ… CapacitÃ© bornÃ©e â†’ Ã©vite saturation mÃ©moire
- âœ… FIFO strict â†’ Ã©quitÃ© de traitement
- âœ… Thread-safe â†’ utilisable par N threads
- âœ… Shutdown gracieux â†’ arrÃªt propre sans deadlock

### 5. RÃ©sultats ExpÃ©rimentaux

#### Benchmark avec 300 Clients SimultanÃ©s

| MÃ©trique | Mono-thread | Multi-thread | AmÃ©lioration |
|----------|-------------|--------------|--------------|
| **Throughput** | 9.2 req/s | 78.5 req/s | **8.5Ã—** ğŸš€ |
| **Latence P50** | 5.4 s | 0.12 s | **45Ã—** ğŸš€ |
| **Latence P99** | 29.1 s | 0.48 s | **60Ã—** ğŸš€ |
| **CPU Usage** | 12% (1 core) | 95% (8 cores) | **8Ã— mieux** |
| **Memory** | 8 MB | 12 MB | +50% acceptable |

#### Speedup ThÃ©orique vs RÃ©el
```
Speedup thÃ©orique = N workers = 8
Speedup rÃ©el mesurÃ© â‰ˆ 6.5-7.0

Perte de 12-18% due Ã  :
- Overhead de synchronisation (mutex lock/unlock)
- Context switching entre threads
- Contention sur accept() (un seul socket)
```

### 6. Cas d'Usage

#### Quand utiliser Mono-thread ?
- âœ… Charge faible (<10 req/s)
- âœ… Traitement ultra-rapide (<1ms)
- âœ… SimplicitÃ© critique (embedded systems)
- âœ… Pas besoin de scalabilitÃ©

#### Quand utiliser Multi-thread ?
- âœ… Charge Ã©levÃ©e (>50 req/s)
- âœ… Traitement CPU-bound (calculs lourds)
- âœ… Latence critique (temps de rÃ©ponse)
- âœ… Exploitation multi-cÅ“urs obligatoire

---

# ğŸ› ï¸ Installation

## âš¡ Installation Rapide

```bash
# Installation complÃ¨te en une commande
./setup.sh
```

Ou manuellement :

## 1ï¸âƒ£ PrÃ©requis systÃ¨me (Ubuntu / Debian)

```bash
sudo apt update
sudo apt install -y build-essential python3 python3-venv python3-pip curl netcat make git
```

DÃ©pendances Python pour les benchmarks :

```bash
pip install psutil pandas matplotlib plotly kaleido
```

---

## 2ï¸âƒ£ Cloner le projet

```bash
git clone https://github.com/.../SERVER_BENCH.git
cd server_project
```

---

## 3ï¸âƒ£ Compiler les serveurs C

Mode normal :

```bash
make clean
make -j$(nproc)
```

Mode debug avec sanitizers :

```bash
make debug
```

---

## 4ï¸âƒ£ Installer lâ€™environnement Python

```bash
cd python
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## 5ï¸âƒ£ Lancer un benchmark complet

Depuis la racine du projet :

```bash
./scripts/run_all.sh
```

Les rÃ©sultats seront gÃ©nÃ©rÃ©s dans :

```
python/results.json  
python/results.xlsx  
python/figures/*.png
```

Et un Dashboard interactif :

```bash
python/dashboard.html
```

---

## 6ï¸âƒ£ Tester le projet

```bash
./scripts/run_tests.sh
```

---

## 7ï¸âƒ£ Nettoyage complet

```bash
./scripts/clean_project.sh
```

---

# ğŸ“‚ Arborescence du projet

```text
server_project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ serveur_mono.c
â”‚   â”œâ”€â”€ serveur_multi.c
â”‚   â”œâ”€â”€ serveur_mono_http.c
â”‚   â”œâ”€â”€ serveur_multi_http.c
â”‚   â”œâ”€â”€ queue.c / queue.h
â”‚   â”œâ”€â”€ http.c / http.h
â”‚
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ benchmark.py
â”‚   â”œâ”€â”€ client_stress.py
â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”œâ”€â”€ results.json / results.xlsx
â”‚   â”œâ”€â”€ figures/
â”‚
â”œâ”€â”€ presentation/
â”‚   â”œâ”€â”€ presentation_finale_serveur.pptx
â”‚   â”œâ”€â”€ script_presentation.pdf
â”‚   â””â”€â”€ backgrounds/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_all.sh
â”‚   â”œâ”€â”€ run_servers.sh
â”‚   â”œâ”€â”€ run_tests.sh
â”‚   â”œâ”€â”€ clean_project.sh
â”‚   â””â”€â”€ open_dashboard.sh
â”‚
â””â”€â”€ rebuild_project.py
```

---

# ğŸ§  UML â€” Architecture & Threads

## UML 1 â€” Architecture globale

![UML Architecture](docs/docs/uml/uml_architecture.png)

---

## UML 2 â€” Queue FIFO Thread-Safe

![UML Queue FIFO](docs/docs/uml/uml_queue.png)

---

## UML 3 â€” Multi-threading (Workers & Dispatcher)

![UML Multi-thread](docs/docs/uml/uml_threads.png)

### Versions SVG (optionnel â€” plus propre pour LaTeX et zoom HD)

```html
<img src="docs/docs/uml/uml_architecture.svg" width="600">
<img src="docs/docs/uml/uml_queue.svg" width="600">
<img src="docs/docs/uml/uml_threads.svg" width="600">

---

# ğŸ“Š RÃ©sultats Benchmark (images gÃ©nÃ©rÃ©es)

## Throughput (req/s)

![Throughput](python/figures/1-throughput.png)

## Latence P99

![Latency P99](python/figures/2-latency_p99.png)

## CPU Usage

![CPU](python/figures/3-cpu.png)

## MÃ©moire

![Memory](python/figures/4-memory.png)

## Speedup Multi-thread

![Speedup](python/figures/5-speedup.png)

---

## ğŸ§ª Tests et Validation

### Tests Unitaires
```bash
make test              # Tests queue FIFO
./bin/test_queue       # Tests d'intÃ©gritÃ©
```

### Tests de Charge
```bash
# Benchmark complet (10â†’300 clients)
./scripts/run_all.sh

# Test manuel mono-thread
./bin/serveur_mono &
python3 python/client_stress.py --port 5050 --clients 100

# Test manuel multi-thread
./bin/serveur_multi &
python3 python/client_stress.py --port 5051 --clients 300
```

### Validation MÃ©moire
```bash
# DÃ©tection fuites mÃ©moires
valgrind --leak-check=full ./bin/serveur_multi

# DÃ©tection race conditions
valgrind --tool=helgrind ./bin/serveur_multi

# Mode debug avec sanitizers
make debug
./bin/serveur_multi
```

---

# ğŸ› ï¸ ExÃ©cution des serveurs

```bash
make run_mono
make run_multi
make run_mono_http
make run_multi_http
```

Stopper :

```bash
make kill_servers
```

---

# ğŸ¤ PrÃ©sentation acadÃ©mique

```
presentation/presentation_finale_serveur.pptx
presentation/script_presentation.pdf
```

Inclut :

* UML
* Architecture serveur
* ExpÃ©rimentation
* Analyse des performances

---

# ğŸ‘¤ **Auteurs â€” Membres du groupe**

| Membre                 | RÃ´le                                     | Expertise                           |
| ---------------------- | ---------------------------------------- | ----------------------------------- |
| **Walid Ben Touhami**  | Serveur multi-thread, Benchmarks, DevOps | Multi-threading, queue, performance |
| **Yassin Ben Aoun**    | Parsing HTTP, serveurs HTTP              | HTTP 1.1, robustesse protocolaire   |
| **Ghada Sakouhi**      | Architecture & queue gÃ©nÃ©rique           | UML, synchronisation                |
| **Islem Ben Chaabene** | Serveur TCP mono-thread                  | C bas-niveau, sockets               |

---

## ğŸš§ DÃ©fis Techniques RencontrÃ©s

Voir documentation dÃ©taillÃ©e : [docs/CHALLENGES.md](docs/CHALLENGES.md)

**RÃ©sumÃ© des principaux dÃ©fis :**
- ğŸ› **Race Conditions** : AccÃ¨s concurrent Ã  la queue â†’ solution avec mutex
- ğŸ”’ **Deadlock** : Shutdown bloquÃ© â†’ solution avec pthread_cond_broadcast()
- ğŸ’¾ **Fuites MÃ©moires** : malloc sans free â†’ dÃ©tection Valgrind
- âš¡ **Saturation** : Queue trop petite â†’ augmentation capacitÃ©
- ğŸ”§ **CohÃ©rence** : DonnÃ©es corrompues â†’ stratÃ©gies d'atomicitÃ©

**Outils utilisÃ©s :**
- Valgrind (memcheck + helgrind)
- GDB avec breakpoints conditionnels
- AddressSanitizer + UndefinedBehaviorSanitizer
- Tests de charge progressifs (10â†’500 clients)

---

# ğŸ“„ Licence

```
MIT License â€” usage acadÃ©mique et professionnel autorisÃ©
```

